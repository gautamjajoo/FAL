{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Federated classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T12:22:45.433829Z",
     "start_time": "2023-07-05T12:22:45.422981Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tensorboardX import SummaryWriter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from torch.utils.data import TensorDataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "\n",
    "file_path = '/Users/gautamjajoo/Desktop/FAL/dataset/Edge-IIoTset/DNN-EdgeIIoT-dataset.csv'\n",
    "from dataset.data import preprocess_dataset, split_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T12:22:45.449460Z",
     "start_time": "2023-07-05T12:22:45.440360Z"
    }
   },
   "outputs": [],
   "source": [
    "# This function takes a list of model weights (each model weight being a dictionary), averages them and returns the average weights\n",
    "def average_weights(w):\n",
    "    \"\"\"\n",
    "    Returns the average of the weights.\n",
    "    \"\"\"\n",
    "    w_avg = copy.deepcopy(w[0])\n",
    "    for key in w_avg.keys():\n",
    "        for i in range(1, len(w)):\n",
    "            w_avg[key] += w[i][key]\n",
    "        w_avg[key] = torch.div(w_avg[key], len(w))\n",
    "    return w_avg\n",
    "\n",
    "\n",
    "\n",
    "#This function splits a dataset into a number of independent and identically distributed (IID) subsets. It is done in such a way that each user or client receives a unique set of samples.\n",
    "\n",
    "def split_iid(dataset, num_users):\n",
    "    num_items = int(len(dataset)/num_users) # the number of allocated samples for each client\n",
    "    dict_users, all_idxs = {}, [i for i in range (len(dataset))]\n",
    "    for i in range (num_users):\n",
    "        dict_users[i] = set(np.random.choice(all_idxs, num_items, replace=False))\n",
    "        all_idxs = list (set(all_idxs) - dict_users[i])\n",
    "    return dict_users \n",
    "\n",
    "\n",
    "# This function reads the training and test data from a csv file, \n",
    "#performs some preprocessing operations and returns a TensorDataset for both training and test data. \n",
    "#It also splits the training data into multiple subsets using the unlabeled_iid() function and returns these user groups\n",
    "def get_dataset(options):\n",
    "    \n",
    "    \n",
    "    #print(\"x_shape\", x.shape)\n",
    "    df = preprocess_dataset(file_path)\n",
    "    num_classes = df['Attack_type'].nunique()\n",
    "    input_features = df.drop(['Attack_type'], axis=1).shape[1]\n",
    "\n",
    "    print(\"Number of classes:\", num_classes)\n",
    "    print(\"Number of input features:\", input_features)\n",
    "    # X_train, X_val, X_test, y_train, y_val, y_test = split_dataset(df, seed=args.seed, size=args.size)\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = split_dataset(df, seed=1, size=0.5)\n",
    "\n",
    "    # Print the shapes of the resulting datasets\n",
    "    print(\"Training set shape:\", X_train.shape)\n",
    "    print(\"Validation set shape:\", X_val.shape)\n",
    "    print(\"Test set shape:\", X_test.shape)\n",
    "\n",
    "    # file_labeled_train = \\\n",
    "    #     pd.read_csv('/Users/gautamjajoo/Desktop/FAL/dataset/Edge-IIoTset/DNN-EdgeIIoT-dataset.csv', skiprows=0, sep=',')\n",
    "    # x_train=file_labeled_train.values[:, 0:30]\n",
    "    # y_train=file_labeled_train.values[:, 30]\n",
    "\n",
    "    #y_train=pd.get_dummies(y_train)\n",
    "    #y_train = y_train.astype(np.float32)\n",
    "    #print(y_train.dtypes)\n",
    "    #y_train = y_train.to_numpy()\n",
    "\n",
    "    # print(\"y_train_shape\", y_train.shape)\n",
    "    # print(\"y_train\", y_train)\n",
    "\n",
    "    #y_class=len(set(y_train))\n",
    "    #print(\"y_class\", y_class)\n",
    "\n",
    "    \n",
    "    # file_labeled_test = pd.read_csv('IIoT_edge_base_classifier_pred_test_new.csv', skiprows=0, sep=',')\n",
    "    # x_test=file_labeled_test.values[:, 0:30]\n",
    "    # y_test=file_labeled_test.values[:, 30]\n",
    "\n",
    "    #y_test=pd.get_dummies(y_test)\n",
    "    #print(y_test.dtypes)\n",
    "    #y_test = y_test.astype(np.float32)\n",
    "    #y_test = y_test.to_numpy()\n",
    "\n",
    "    # print(\"y_test_shape\", y_test.shape)\n",
    "    # print(\"y_test\", y_test)\n",
    "\n",
    "    #y_class_test=len(set(y_test))\n",
    "    #print(\"y_class_test\", y_class_test)\n",
    "    \n",
    "    #raise\n",
    "    \n",
    "    #train_data\n",
    "    #x_train=pd.DataFrame(x_test)\n",
    "    #y_train=pd.DataFrame(y)\n",
    "\n",
    "    #train_data=pd.concat([x_train, y_train],axis=1)\n",
    "    #print(\"train_data\", train_data.shape)\n",
    "    \n",
    "    #train_data.to_csv('IIoT_edge_base_classifier_pred_dummies.csv',index=False)\n",
    "\n",
    "    #test_data\n",
    "    #x_test=pd.DataFrame(x_test)\n",
    "    #y_test=pd.DataFrame(y_test)\n",
    "\n",
    "    #test_data=pd.concat([x_val, y_val], axis=1)\n",
    "    #print(\"test_data\", test_data.shape)\n",
    "    \n",
    "    #train_data.to_csv('IIoT_edge_base_classifier_pred_test_dummies.csv',index=False)\n",
    "\n",
    "    \n",
    "    #x_train_l,x_test,y_train_l,y_test=train_test_split(x_l, y ,random_state=0, test_size=0.5)\n",
    "    \n",
    "    #print(x_train_l.dtype) # This should not be 'object'\n",
    "    \n",
    "    #train_data = train_data.astype(float)\n",
    "    #test_data = test_data.astype(float)\n",
    "    #y_train_l = y_train_l.astype(float)\n",
    "    #y_test=y_test.astype(float)\n",
    "\n",
    "    #sc = MinMaxScaler()\n",
    "    #x_train_l = sc.fit_transform(x_train_l)\n",
    "    #x_test_l = sc.transform(x_test_l)\n",
    "    \n",
    "    #scaler=StandardScaler()\n",
    "    #x_train_l=scaler.fit_transform(x_train_l)\n",
    "    #x_test=scaler.fit_transform(x_test)\n",
    "    \n",
    "    #scaler=StandardScaler()\n",
    "    #x_train=scaler.fit_transform(x_train)\n",
    "    #x_test=scaler.fit_transform(x_test)\n",
    "\n",
    "    X_train_tensor = torch.Tensor(X_train.values)\n",
    "    y_train_tensor = torch.LongTensor(y_train.values)\n",
    "\n",
    "    train_dataset = TensorDataset(torch.from_numpy(X_train_tensor),torch.from_numpy(y_train_tensor))\n",
    "\n",
    "    X_test_tensor = torch.Tensor(X_test.values)\n",
    "    y_test_tensor = torch.LongTensor(y_test.values)\n",
    "\n",
    "    test_dataset = TensorDataset(torch.from_numpy(X_test_tensor),torch.from_numpy(y_test_tensor))\n",
    "\n",
    "    \n",
    "    # train_dataset = TensorDataset(torch.from_numpy(x_train),torch.from_numpy(y_train))\n",
    "    # test_dataset = TensorDataset(torch.from_numpy(x_test),torch.from_numpy(y_test))\n",
    "\n",
    "    \n",
    "    \n",
    "    #train_dataset = TensorDataset(torch.from_numpy(train_data))\n",
    "    #test_dataset = TensorDataset(torch.from_numpy(test_data))\n",
    "\n",
    "    \n",
    "    #sc = MinMaxScaler()\n",
    "    #unlabeled_dataset = sc.fit_transform(x)\n",
    "\n",
    "    \n",
    "    \n",
    "    #Feature scaling\n",
    "    #sc = StandardScaler()\n",
    "    #unlabeled_dataset = sc.fit_transform(x)\n",
    "\n",
    "    #converting to torch tensor\n",
    "    #train_dataset = torch.tensor(train_dataset, dtype=torch.float32)\n",
    "    #test_dataset = torch.tensor(test_dataset, dtype=torch.float32)\n",
    "\n",
    "    #print(\"train_dataset\")\n",
    "\n",
    "    \n",
    "    user_groups = split_iid(train_dataset, options.num_users)\n",
    "    print(\"user_group\", user_groups)\n",
    "    print(\"Done...\")\n",
    "    return train_dataset, test_dataset, user_groups\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#This class is a custom dataset that receives a base dataset and a list of indices. \n",
    "#It enables getting only a subset of the data in the base dataset, as specified by the indices list. \n",
    "#This is helpful in a federated learning scenario, where each client might only have access to a subset of the total data.\n",
    "class DatasetSplit(Dataset):\n",
    "    def __init__(self, dataset, idxs):\n",
    "        self.dataset = dataset\n",
    "        self.idxs = [int(i) for i in idxs]\n",
    "    def __len__(self):\n",
    "        return len(self.idxs)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        \n",
    "        data, target = self.dataset[self.idxs[item]]\n",
    "        return torch.tensor(data), torch.tensor(target)\n",
    "\n",
    "        #data = self.dataset[self.idxs[item]]\n",
    "        #return torch.tensor(data), torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T12:22:45.450797Z",
     "start_time": "2023-07-05T12:22:45.447098Z"
    }
   },
   "outputs": [],
   "source": [
    "#set program arguments\n",
    "options = lambda: None\n",
    "options.rounds= 10\n",
    "options.num_users= 15\n",
    "options.frac= 1\n",
    "options.local_ep= 10\n",
    "options.local_bs= 10\n",
    "options.lr= 0.01\n",
    "options.momentum= 0.5\n",
    "options.model= \"mlp\"\n",
    "options.kernel_num= 9\n",
    "options.kernel_sizes= \"3,4,5\"\n",
    "options.num_channels= 1\n",
    "options.norm= \"batch_norm\"\n",
    "options.num_filters= 32\n",
    "options.max_pool= \"True\"\n",
    "options.dataset= \"mnist\"\n",
    "options.num_classes= 15\n",
    "options.gpu= None\n",
    "options.optimizer= \"sgd\"\n",
    "options.iid= 1\n",
    "options.unequal= 0\n",
    "options.stopping_rounds= 10\n",
    "options.verbose= 1\n",
    "options.seed= 1\n",
    "options.batch_size = 100\n",
    "options.client_epochs = 50\n",
    "options.server_epochs=20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T12:22:45.459943Z",
     "start_time": "2023-07-05T12:22:45.457362Z"
    }
   },
   "outputs": [],
   "source": [
    "input_size = n_features=75\n",
    "num_classes = 15\n",
    "# hidden_size = [100, 100, 15]\n",
    "hidden_size = [2, 90]\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# class MLP(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(MLP, self).__init__()\n",
    "#         self.MLP= nn.Sequential(\n",
    "#         nn.Linear(input_size, hidden_size[0]),\n",
    "#         nn.ReLU(),\n",
    "#         nn.Dropout(0.01),\n",
    "#         nn.Linear(hidden_size[0], hidden_size[1]),\n",
    "#         nn.ReLU(),\n",
    "#         nn.Dropout(0.01),\n",
    "#         nn.Linear(hidden_size[1], hidden_size[2]))\n",
    "#         #nn.Softmax())\n",
    "#\n",
    "#     def forward(self, x):\n",
    "#         x=self.MLP(x)\n",
    "#         return x\n",
    "\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        # input layer\n",
    "        self.layers.append(nn.Linear(input_size, hidden_size[1]))\n",
    "        self.layers.append(nn.ReLU())\n",
    "\n",
    "        # hidden layers\n",
    "        for _ in range(hidden_size[0] - 1):\n",
    "            self.layers.append(nn.Linear(hidden_size[1], hidden_size[1]))\n",
    "            self.layers.append(nn.ReLU())\n",
    "\n",
    "        # output layer\n",
    "        self.layers.append(nn.Linear(hidden_size[1], num_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        # Applying the softmax function to the output layer\n",
    "        x = nn.functional.softmax(x, dim=1)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T12:22:45.479019Z",
     "start_time": "2023-07-05T12:22:45.474789Z"
    }
   },
   "outputs": [],
   "source": [
    "class DNNModel(object):\n",
    "    def __init__(self, options, train_dataset, test_dataset, idxs, logger):\n",
    "        \n",
    "        self.options = options\n",
    "        self.logger = logger\n",
    "        self.train_loader = DataLoader(DatasetSplit(train_dataset, idxs),\n",
    "                             batch_size=options.batch_size, shuffle=True)\n",
    "        self.test_loader= DataLoader(test_dataset, batch_size= options.batch_size, shuffle=False)\n",
    "\n",
    "        #size=sys.getsizeof(self.train_loader)\n",
    "        #print(\"data_user\", size)\n",
    "        self.device = 'cuda' if options.gpu else 'cpu'\n",
    "        # Default criterion set to NLL loss function\n",
    "        #self.criterion = nn.NLLLoss()\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        #self.criterion= nn.BCELoss()\n",
    "        self.client_epochs=options.client_epochs\n",
    "        self.net=DNN().to(device)\n",
    "        self.optimizer = optim.Adam(self.net.parameters(), lr=0.01)\n",
    "\n",
    "        self.history = {}\n",
    "        self.history['train_loss'] = []\n",
    "        self.history['test_loss'] = []\n",
    "\n",
    "    def train(self, model):\n",
    "        mean_losses_superv = []\n",
    "        #self.net.train()\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for epoch in range(self.options.client_epochs):\n",
    "            h = np.array([])\n",
    "            \n",
    "            for x, y in self.train_loader:\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                x=x.float()\n",
    "                \n",
    "                output = self.net(x)\n",
    "                \n",
    "                y=y.long()\n",
    "                \n",
    "                loss = self.criterion(output, y)\n",
    "                h = np.append(h, loss.item())\n",
    "                #raise\n",
    "                \n",
    "        # ===================backward====================\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                output = output.argmax(axis=1)\n",
    "                \n",
    "                total += y.size(0)\n",
    "                \n",
    "                y=y.float()\n",
    "                output=output.float()\n",
    "                \n",
    "                correct += (output == y).sum().item()\n",
    "                \n",
    "        #raise\n",
    "        # ===================log========================\n",
    "            mean_loss_superv = np.mean(h)\n",
    "            train_acc=correct/total\n",
    "            \n",
    "            mean_losses_superv.append(mean_loss_superv)\n",
    "            PATH = \"state_dict_model_Sup_IIoT_edge.pt\"\n",
    "            # Save\n",
    "            torch.save(self.net.state_dict(), PATH)\n",
    "            return sum(mean_losses_superv) / len(mean_losses_superv) , train_acc, self.net.state_dict() \n",
    "            #print('Done.....')\n",
    "\n",
    "   \n",
    "    def test_inference(self, model, test_dataset):\n",
    "        nb_classes = 15\n",
    "        confusion_matrix = np.zeros((nb_classes, nb_classes))\n",
    "        self.net.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        output_list=torch.zeros(0,dtype=torch.long)\n",
    "        target_list=torch.zeros(0,dtype=torch.long)\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            for data, target in self.test_loader:\n",
    "                \n",
    "                data, target = data.to(device), target.to(device)\n",
    "        \n",
    "                \n",
    "                output = self.net(data.float())\n",
    "                \n",
    "                batch_loss = self.criterion(output, target.long())\n",
    "                #print(\"done... test...\")\n",
    "                #raise\n",
    "                test_loss += batch_loss.item()\n",
    "                total += target.size(0)\n",
    "                \n",
    "                \n",
    "\n",
    "                target=target.float()\n",
    "                \n",
    "                output=output.argmax(axis=1)\n",
    "                output=output.float()\n",
    "                \n",
    "                \n",
    "                output_list=torch.cat([output_list, output.view(-1).long()])\n",
    "                target_list=torch.cat([target_list, target.view(-1).long()])\n",
    "                \n",
    "        \n",
    "                correct += (output == target).sum().item()\n",
    "        \n",
    "                    \n",
    "            test_loss/=total\n",
    "            acc=correct/total\n",
    "       \n",
    "    \n",
    "            F1_score= f1_score(target_list, output_list, average = \"macro\") #labels=np.unique(output_list))))\n",
    "            Precision=precision_score(target_list, output_list, average=\"macro\")                                      \n",
    "            Recall=recall_score(target_list, output_list, average=\"macro\")\n",
    "            class_report=classification_report(target_list,output_list, digits=4)\n",
    "\n",
    "            #print(' F1 Score : ' + str(f1_score(target_list, output_list, average = \"macro\"))) #labels=np.unique(output_list))))\n",
    "            #print(' Presicion : '+str(precision_score(target_list, output_list, average=\"macro\", labels=np.unique(output_list))))                                       \n",
    "            #print(' Recall : '+str(recall_score(target_list, output_list, average=\"macro\", labels=np.unique(output_list))))\n",
    "            #print(\"report\", classification_report(target_list,output_list, digits=4))\n",
    "\n",
    "            return acc, F1_score, Precision, Recall, class_report, test_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T12:24:26.283410Z",
     "start_time": "2023-07-05T12:22:45.481028Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack_type\n",
      "Normal                   1615643\n",
      "DDoS_UDP                  121568\n",
      "DDoS_ICMP                 116436\n",
      "SQL_injection              51203\n",
      "Password                   50153\n",
      "Vulnerability_scanner      50110\n",
      "DDoS_TCP                   50062\n",
      "DDoS_HTTP                  49911\n",
      "Uploading                  37634\n",
      "Backdoor                   24862\n",
      "Port_Scanning              22564\n",
      "XSS                        15915\n",
      "Ransomware                 10925\n",
      "MITM                        1214\n",
      "Fingerprinting              1001\n",
      "Name: count, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1909671 entries, 0 to 2219193\n",
      "Data columns (total 97 columns):\n",
      " #   Column                                                                                                Dtype  \n",
      "---  ------                                                                                                -----  \n",
      " 0   arp.opcode                                                                                            float64\n",
      " 1   arp.hw.size                                                                                           float64\n",
      " 2   icmp.checksum                                                                                         float64\n",
      " 3   icmp.seq_le                                                                                           float64\n",
      " 4   icmp.unused                                                                                           float64\n",
      " 5   http.content_length                                                                                   float64\n",
      " 6   http.response                                                                                         float64\n",
      " 7   http.tls_port                                                                                         float64\n",
      " 8   tcp.ack                                                                                               float64\n",
      " 9   tcp.ack_raw                                                                                           float64\n",
      " 10  tcp.checksum                                                                                          float64\n",
      " 11  tcp.connection.fin                                                                                    float64\n",
      " 12  tcp.connection.rst                                                                                    float64\n",
      " 13  tcp.connection.syn                                                                                    float64\n",
      " 14  tcp.connection.synack                                                                                 float64\n",
      " 15  tcp.flags                                                                                             float64\n",
      " 16  tcp.flags.ack                                                                                         float64\n",
      " 17  tcp.len                                                                                               float64\n",
      " 18  tcp.seq                                                                                               float64\n",
      " 19  udp.stream                                                                                            float64\n",
      " 20  udp.time_delta                                                                                        float64\n",
      " 21  dns.qry.name                                                                                          float64\n",
      " 22  dns.qry.qu                                                                                            float64\n",
      " 23  dns.qry.type                                                                                          float64\n",
      " 24  dns.retransmission                                                                                    float64\n",
      " 25  dns.retransmit_request                                                                                float64\n",
      " 26  dns.retransmit_request_in                                                                             float64\n",
      " 27  mqtt.conflag.cleansess                                                                                float64\n",
      " 28  mqtt.conflags                                                                                         float64\n",
      " 29  mqtt.hdrflags                                                                                         float64\n",
      " 30  mqtt.len                                                                                              float64\n",
      " 31  mqtt.msg_decoded_as                                                                                   float64\n",
      " 32  mqtt.msgtype                                                                                          float64\n",
      " 33  mqtt.proto_len                                                                                        float64\n",
      " 34  mqtt.topic_len                                                                                        float64\n",
      " 35  mqtt.ver                                                                                              float64\n",
      " 36  mbtcp.len                                                                                             float64\n",
      " 37  mbtcp.trans_id                                                                                        float64\n",
      " 38  mbtcp.unit_id                                                                                         float64\n",
      " 39  Attack_label                                                                                          int64  \n",
      " 40  Attack_type                                                                                           int64  \n",
      " 41  http.request.method-0                                                                                 bool   \n",
      " 42  http.request.method-0.0                                                                               bool   \n",
      " 43  http.request.method-GET                                                                               bool   \n",
      " 44  http.request.method-OPTIONS                                                                           bool   \n",
      " 45  http.request.method-POST                                                                              bool   \n",
      " 46  http.request.method-PROPFIND                                                                          bool   \n",
      " 47  http.request.method-PUT                                                                               bool   \n",
      " 48  http.request.method-SEARCH                                                                            bool   \n",
      " 49  http.request.method-TRACE                                                                             bool   \n",
      " 50  http.referer-() { _; } >_[$($())] { echo 93e4r0-CVE-2014-6278: true; echo;echo; }                     bool   \n",
      " 51  http.referer-0                                                                                        bool   \n",
      " 52  http.referer-0.0                                                                                      bool   \n",
      " 53  http.referer-127.0.0.1                                                                                bool   \n",
      " 54  http.referer-TESTING_PURPOSES_ONLY                                                                    bool   \n",
      " 55  http.request.version--a HTTP/1.1                                                                      bool   \n",
      " 56  http.request.version--al&ABSOLUTE_PATH_STUDIP=http://cirt.net/rfiinc.txt?? HTTP/1.1                   bool   \n",
      " 57  http.request.version--al&_PHPLIB[libdir]=http://cirt.net/rfiinc.txt?? HTTP/1.1                        bool   \n",
      " 58  http.request.version-/etc/passwd|?data=Download HTTP/1.1                                              bool   \n",
      " 59  http.request.version-0                                                                                bool   \n",
      " 60  http.request.version-0.0                                                                              bool   \n",
      " 61  http.request.version-> HTTP/1.1                                                                       bool   \n",
      " 62  http.request.version-By Dr HTTP/1.1                                                                   bool   \n",
      " 63  http.request.version-HTTP/1.0                                                                         bool   \n",
      " 64  http.request.version-HTTP/1.1                                                                         bool   \n",
      " 65  http.request.version-Src=javascript:alert('Vulnerable')><Img Src=\\\" HTTP/1.1                          bool   \n",
      " 66  http.request.version-name=a><input name=i value=XSS>&lt;script>alert('Vulnerable')</script> HTTP/1.1  bool   \n",
      " 67  http.request.version-script>alert(1)/script><\\\" HTTP/1.1                                              bool   \n",
      " 68  dns.qry.name.len-0                                                                                    bool   \n",
      " 69  dns.qry.name.len-0.0                                                                                  bool   \n",
      " 70  dns.qry.name.len-0.debian.pool.ntp.org                                                                bool   \n",
      " 71  dns.qry.name.len-1.0                                                                                  bool   \n",
      " 72  dns.qry.name.len-1.debian.pool.ntp.org                                                                bool   \n",
      " 73  dns.qry.name.len-2.debian.pool.ntp.org                                                                bool   \n",
      " 74  dns.qry.name.len-3.debian.pool.ntp.org                                                                bool   \n",
      " 75  dns.qry.name.len-_googlecast._tcp.local                                                               bool   \n",
      " 76  dns.qry.name.len-null-null.local                                                                      bool   \n",
      " 77  dns.qry.name.len-raspberrypi.local                                                                    bool   \n",
      " 78  mqtt.conack.flags-0                                                                                   bool   \n",
      " 79  mqtt.conack.flags-0.0                                                                                 bool   \n",
      " 80  mqtt.conack.flags-0x00000000                                                                          bool   \n",
      " 81  mqtt.conack.flags-1461073                                                                             bool   \n",
      " 82  mqtt.conack.flags-1461074                                                                             bool   \n",
      " 83  mqtt.conack.flags-1461383                                                                             bool   \n",
      " 84  mqtt.conack.flags-1461384                                                                             bool   \n",
      " 85  mqtt.conack.flags-1461589                                                                             bool   \n",
      " 86  mqtt.conack.flags-1461591                                                                             bool   \n",
      " 87  mqtt.conack.flags-1471198                                                                             bool   \n",
      " 88  mqtt.conack.flags-1471199                                                                             bool   \n",
      " 89  mqtt.conack.flags-1574358                                                                             bool   \n",
      " 90  mqtt.conack.flags-1574359                                                                             bool   \n",
      " 91  mqtt.protoname-0                                                                                      bool   \n",
      " 92  mqtt.protoname-0.0                                                                                    bool   \n",
      " 93  mqtt.protoname-MQTT                                                                                   bool   \n",
      " 94  mqtt.topic-0                                                                                          bool   \n",
      " 95  mqtt.topic-0.0                                                                                        bool   \n",
      " 96  mqtt.topic-Temperature_and_Humidity                                                                   bool   \n",
      "dtypes: bool(56), float64(39), int64(2)\n",
      "memory usage: 713.9 MB\n",
      "None\n",
      "Number of classes: 15\n",
      "Number of input features: 79\n",
      "Training set shape: (954835, 79)\n",
      "Validation set shape: (477418, 79)\n",
      "Test set shape: (477418, 79)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m logger \u001b[38;5;241m=\u001b[39m SummaryWriter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../logs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#load data\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m train_dataset, test_dataset,user_groups\u001b[38;5;241m=\u001b[39m\u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 121\u001b[0m, in \u001b[0;36mget_dataset\u001b[0;34m(options)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest set shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_test\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# file_labeled_train = \\\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m#     pd.read_csv('/Users/gautamjajoo/Desktop/FAL/dataset/Edge-IIoTset/DNN-EdgeIIoT-dataset.csv', skiprows=0, sep=',')\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# x_train=file_labeled_train.values[:, 0:30]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m#x_train=scaler.fit_transform(x_train)\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m#x_test=scaler.fit_transform(x_test)\u001b[39;00m\n\u001b[0;32m--> 121\u001b[0m X_train_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m y_train_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mLongTensor(y_train\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m    124\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m TensorDataset(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(X_train_tensor),torch\u001b[38;5;241m.\u001b[39mfrom_numpy(y_train_tensor))\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "logger = SummaryWriter('../logs')\n",
    "#load data\n",
    "train_dataset, test_dataset,user_groups=get_dataset(options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-05T12:24:26.245701Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# BUILD MODEL\n",
    "#global_model=MLPModel(options=options, train_dataset=train_dataset, test_dataset=test_dataset, logger=logger)\n",
    "DNN_model=DNN()\n",
    "print(DNN_model)\n",
    "# Training\n",
    "train_loss, train_accuracy = [], []\n",
    "val_acc_list, net_list = [], []\n",
    "cv_loss, cv_acc = [], []\n",
    "print_every = 2\n",
    "val_loss_pre, counter = 0, 0\n",
    "\n",
    "for rounds in tqdm(range(options.rounds)):\n",
    "    # in the server\n",
    "    local_weights, local_losses = [], []\n",
    "    print(f'\\n | Training Round : {rounds+1} |\\n')\n",
    "    \n",
    "    #global_model.train(auto_encoder_model)\n",
    "    m = max(int(options.frac * options.num_users), 1)\n",
    "    idxs_users = np.random.choice(range(options.num_users), m, replace=False)\n",
    "    print(\"idxs_users\",idxs_users)\n",
    "\n",
    "    \n",
    "    \n",
    "    for idx in idxs_users:\n",
    "        DNN_client = DNNModel(options=options, train_dataset=train_dataset, test_dataset=test_dataset,\n",
    "                                    idxs=user_groups[idx], logger=logger)\n",
    "        loss, train_acc, w = DNN_client.train(model=copy.deepcopy(DNN_model))\n",
    "        #print(w)\n",
    "        #print(\"w\", w)\n",
    "        #print(\"loss\", loss)\n",
    "        local_weights.append(copy.deepcopy(w))\n",
    "        #local_losses.append(copy.deepcopy(loss))\n",
    "        \n",
    "        test_acc, F1_score, Precision, Recall, class_report, test_loss = DNN_client.test_inference(DNN_model, test_dataset)\n",
    "        print(f'client_id {idx}')\n",
    "        print(\"|---- Test Accuracy_client: {:.2f}%\".format(test_acc))\n",
    "        print(\"|---- F1_score:\", F1_score)\n",
    "        print(\"|---- Precision:\", Precision)\n",
    "        print(\"|---- Recall:\", Recall)\n",
    "        print(class_report)\n",
    "        print(f'Testing Loss : {np.mean(np.array(test_loss))}')\n",
    "    #print(local_weights)\n",
    "    DNN_model.load_state_dict(average_weights(local_weights))\n",
    "    #loss_avg = sum(local_losses) / len(local_losses)\n",
    "    #train_loss.append(loss_avg)\n",
    "    \n",
    "    #mean_losses_superv = global_model.train(auto_encoder_model)\n",
    "    #mean_losses_superv_avg = sum(mean_losses_superv) / len(mean_losses_superv)\n",
    "    \n",
    "    \n",
    "   \n",
    "    # Calculate avg training accuracy over all users at every epoch\n",
    "    #list_acc, list_loss = [], []\n",
    "    #auto_encoder_model.eval()\n",
    "    #for c in range(options.num_users):\n",
    "        #local_model = AutoEncoder(options=options, dataset=train_dataset,\n",
    "                                       #idxs=user_groups[idx], logger=logger)\n",
    "        #acc, loss = auto_encoder.inference(model=auto_encoder_model)\n",
    "        #list_acc.append(acc)\n",
    "        #list_loss.append(loss)\n",
    "    #train_accuracy.append(sum(list_acc)/len(list_acc))\n",
    "\n",
    "    # print global training loss after every 'i' rounds\n",
    "    #if (round+1) % print_every == 0:\n",
    "        #print(f' \\nAvg Training Stats after {round+1} global rounds:')\n",
    "        #print(f'Training Loss : {np.mean(np.array(train_loss))}')\n",
    "        #print('Train Accuracy: {:.2f}% \\n'.format(100*train_accuracy[-1]))\n",
    "#print(\"yes\")\n",
    "\n",
    "    test_acc_g, F1_score_g, Precision_g, Recall_g, class_report_g, test_loss_g = DNN_client.test_inference(DNN_model, test_dataset)\n",
    "\n",
    "    \n",
    "    #if (rounds+1) % print_every == 0:\n",
    "    print(f' \\nAvg Training Stats after {rounds+1} global rounds:')\n",
    "    print(\"|---- Test Accuracy:\", test_acc_g)\n",
    "    print(\"|---- F1_score:\", F1_score_g)\n",
    "    print(\"|---- Precision:\", Precision_g)\n",
    "    print(\"|---- Recall:\", Recall_g)\n",
    "    print(class_report_g)\n",
    "    #print(f'Training Loss : {np.mean(np.array(mean_losses_superv_avg))}')\n",
    "    print(f'Testing Loss : {np.mean(np.array(test_loss))}')\n",
    "    \n",
    "   \n",
    "        #print(f' \\n Results after {options.rounds} global rounds of training:')\n",
    "#print(\"|---- Avg Train Accuracy: {:.2f}%\".format(100*train_accuracy[-1]))\n",
    "        #print(f'Training Loss : {np.mean(np.array(mean_losses_superv_avg))}')\n",
    "        #print(f'Testing Loss : {np.mean(np.array(test_loss))}')\n",
    "        \n",
    "        #print(\"yes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
