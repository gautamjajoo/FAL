# # active_learning_strategies = ['FedAvg', 'Fedprox(rho=0.3)', 'Fedprox(rho=0.5)', 'Strategy 4']
# import matplotlib.pyplot as plt

# # Sample data (replace this with your actual data)
# number_of_samples = [309797, 359357, 406937, 452617, 496457, 538557, 578957, 617757, 654997, 690737, 725057, 757997, 789617, 819977, 849137, 877117, 903977, 929777, 954537, 978297, 1001117, 1023017, 1044037, 1064217, 1083597, 1102197, 1120057, 1137197, 1153657, 1169457, 1184637, 1199197, 1213177, 1226597, 1239477, 1251857, 1263737, 1275137, 1286077, 1296577, 1306657, 1316337, 1325637, 1334557, 1343117, 1351337, 1359237, 1366817, 1374097, 1381077]
# fedag_accuracy = [0.9313864102886348, 0.9323446860206945, 0.9331039755351682, 0.9333081982321646, 0.9334652926144694, 0.9346906287964476, 0.9346016086464748, 0.9352561685727452, 0.9344759331406309, 0.9356750869255582, 0.9353870805579992, 0.9352038037786435, 0.9349681622051862, 0.9361620795107034, 0.9364762682753132, 0.9362720455783168, 0.9366647815340791, 0.936633362657618, 0.9366543085752587, 0.9366543085752587, 0.9381938335218466, 0.939780486783126, 0.9396862301537431, 0.9395972100037703, 0.9397438314272548, 0.9397438314272548, 0.9396757571949227, 0.9397438314272548, 0.9400632566712748, 0.9400423107536341, 0.9400527837124545, 0.9400894390683255, 0.9397752503037158, 0.9401732227388881, 0.9399166352477902, 0.9407806543504671, 0.9408592015416195, 0.9415504168237611, 0.9417598760001675, 0.9388745758451678, 0.9418436596707301, 0.9421264295588789, 0.9422468685853127, 0.9453835197520003, 0.947368145448452, 0.9462161199782162, 0.9475042939131163, 0.946273721251728, 0.9477137530895229, 0.9475776046248586]

# fedprox_rho_0_3_accuracy = [0.9292813455657493, 0.9318158016002681, 0.932810732688199, 0.933711407146747, 0.9342088726907126, 0.9354499183109212, 0.9354970466256126, 0.9351828578610029, 0.9358059989108123, 0.9363558292488794, 0.9361882619077542, 0.9364867412341334, 0.9375497465543966, 0.9379372460307486, 0.9391206903774454, 0.9388693393657576, 0.9393563319509027, 0.939623392400821, 0.9395343722508483, 0.9397124125507939, 0.9396129194420008, 0.9399690000418919, 0.9401418038624272, 0.940937748732772, 0.9411105525533073, 0.9408487285827992, 0.9409325122533618, 0.9417546395207574, 0.9418646055883708, 0.9419169703824725, 0.9422521050647229, 0.9444828452934523, 0.9442105483641239, 0.9458652758577353, 0.94601713376063, 0.9471377403544049, 0.9472267605043777, 0.9469492270956391, 0.9475461857483977, 0.9474362196807842, 0.9466402748104394, 0.9470173013279711, 0.9473210171337606, 0.946755477357463, 0.9469911189309204, 0.9459752419253488, 0.9464622345104939, 0.9459700054459386, 0.9464255791546228, 0.9460328431988605]

# fedprox_rho_0_5_accuracy = [0.9294070210715931, 0.928118847136693, 0.9335595492438524, 0.9329992459469649, 0.9349000879728541, 0.9357222152402497, 0.9343712035524276, 0.9359054920196054, 0.9340674877466382, 0.9366281261782079, 0.936727619287001, 0.936471031795903, 0.9373978886515019, 0.9375235641573457, 0.9391625822127267, 0.9386651166687613, 0.9386755896275816, 0.9395919735243601, 0.9393929873067739, 0.9402727158476812, 0.93991139876838, 0.9411576808679988, 0.9412624104562021, 0.9405764316534707, 0.9415870721796322, 0.9418436596707301, 0.941901260944242, 0.9422206861882619, 0.9424563277617193, 0.9459909513635792, 0.9457710192283524, 0.9449855473168279, 0.9463208495664195, 0.9455563235725357, 0.9453521008755393, 0.9469911189309204, 0.9442367307611746, 0.9467450043986427, 0.9468654434250765, 0.9448546353315739, 0.9460642620753216, 0.9450536215491601, 0.9417075112060659, 0.9456872355577898, 0.9444514264169913, 0.9444042981022999, 0.9459333500900674, 0.9456243978048678, 0.9418017678354489, 0.9460328431988605]

# fedprox_rho_0_8_accuracy = [0.9264588831636714, 0.8976163545724938, 0.9317005990532445, 0.9262337145490344, 0.9322923212265929, 0.9328526245234804, 0.9345021155376817, 0.9341355619789703, 0.9361568430312932, 0.9379948473042604, 0.9377016044572912, 0.9375392735955762, 0.9386389342717104, 0.9392516023626996, 0.9393249130744418, 0.939717649030204, 0.9395605546478991, 0.9380105567424909, 0.9406916342004943, 0.9388012651334255, 0.9413828494826358, 0.9401103849859662, 0.9377487327719828, 0.940712580118135, 0.9391259268568556, 0.9439539608730259, 0.9445561560051946, 0.9377749151690336, 0.9459700054459386, 0.9460694985547317, 0.9421107201206484, 0.9471377403544049, 0.9392934941979808, 0.9449331825227263, 0.9445404465669641, 0.942770516526329, 0.9450902769050312, 0.9455196682166646, 0.9361934983871644, 0.9453049725608479, 0.9372250848309664, 0.9417127476854761, 0.9383718738217921, 0.94537304679318, 0.9359159649784257, 0.9448755812492146, 0.9340989066230991, 0.9452683172049767, 0.9394820074567467, 0.9459071676930166]


# # Plotting the data
# plt.plot(number_of_samples, fedag_accuracy, label='FedAvg')
# plt.plot(number_of_samples, fedprox_rho_0_3_accuracy, label='FedProx (rho = 0.3)')
# plt.plot(number_of_samples, fedprox_rho_0_5_accuracy, label='FedProx (rho = 0.5)')
# plt.plot(number_of_samples, fedprox_rho_0_8_accuracy, label='FedProx (rho = 0.8)')

# # Adding labels and title
# plt.xlabel('Number of Samples')
# plt.ylabel('Global Accuracy')
# plt.title('Global Accuracy vs Number of Samples')
# plt.legend()

# # Show the plot
# plt.show()


# import matplotlib.pyplot as plt

# # Data
# rounds = list(range(1, 11))
# fedavg = [0.934654, 0.939456, 0.933952, 0.9422, 0.947795, 0.947562, 0.9444451, 0.947852, 0.948334, 0.947931]
# fedprox_03 = [0.854329, 0.939372, 0.940733, 0.947266, 0.947808, 0.947826, 0.948337, 0.948360, 0.948371, 0.948316]
# fedprox_05 = [0.935162, 0.937908, 0.939898, 0.946802, 0.947638, 0.948190, 0.948373, 0.948049, 0.947868, 0.948538]
# fedprox_08 = [0.839871, 0.934219, 0.938126, 0.940736, 0.946745, 0.943956, 0.948164, 0.937518, 0.948224, 0.948211]
# fedprox_1 = [0.933410, 0.907424, 0.933591, 0.911312, 0.944909, 0.932059, 0.947117, 0.947766, 0.948300, 0.948352]

# # Plot
# plt.figure(figsize=(10, 6))
# plt.plot(rounds, fedavg, marker='o', label='FedAvg')
# plt.plot(rounds, fedprox_03, marker='o', label='FedProx(0.3)')
# plt.plot(rounds, fedprox_05, marker='o', label='FedProx(0.5)')
# plt.plot(rounds, fedprox_08, marker='o', label='FedProx(0.8)')
# plt.plot(rounds, fedprox_1, marker='o', label='FedProx(1)')

# # Add labels and title
# plt.xlabel('Round')
# plt.ylabel('Accuracy')
# plt.title('Accuracy vs Round for FedAvg and FedProx')
# plt.legend()

# # Show plot
# plt.grid(True)
# plt.show()

import matplotlib.pyplot as plt

# Data
rounds = list(range(1, 11))
fedavg = [0.934654, 0.939456, 0.933952, 0.9422, 0.947795, 0.947562, 0.9444451, 0.947852, 0.948334, 0.947931]
fedprox_03 = [0.854329, 0.939372, 0.940733, 0.947266, 0.947808, 0.947826, 0.948337, 0.948360, 0.948371, 0.948316]
fedprox_05 = [0.935162, 0.937908, 0.939898, 0.946802, 0.947638, 0.948190, 0.948373, 0.948049, 0.947868, 0.948538]
fedprox_08 = [0.839871, 0.934219, 0.938126, 0.940736, 0.946745, 0.943956, 0.948164, 0.937518, 0.948224, 0.948211]
fedprox_1 = [0.933410, 0.907424, 0.933591, 0.911312, 0.944909, 0.932059, 0.947117, 0.947766, 0.948300, 0.948352]

# Plot
plt.figure(figsize=(10, 6))
plt.plot(rounds, fedavg, marker='o', label='FedAvg')
plt.plot(rounds, fedprox_03, marker='o', label='FedProx(0.3)')
plt.plot(rounds, fedprox_05, marker='o', label='FedProx(0.5)')
plt.plot(rounds, fedprox_08, marker='o', label='FedProx(0.8)')
plt.plot(rounds, fedprox_1, marker='o', label='FedProx(1)')

# Add labels and title
plt.xlabel('Round')
plt.ylabel('Accuracy')
plt.title('Accuracy vs Round(Classical Federated Learning)')
plt.legend()

# Set y-axis limits with some padding for the outlier values
plt.ylim(min(fedprox_08) - 0.005, max(fedavg) + 0.005)

# Show plot
plt.grid(True)
plt.show()

